{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48595e97",
   "metadata": {},
   "source": [
    "Data File - Excel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81dc06b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------\n",
    "# Script: Convert Auditor & Liquidator Excel Sheets to CSV\n",
    "# Description:\n",
    "#   - Reads two sheets (\"REG_AUDITOR_202511\" and \"LIQUIDATOR_202510\")\n",
    "#     from an Excel file\n",
    "#   - Cleans data types (string, dates)\n",
    "#   - Exports results to CSV in destination/excel/\n",
    "# ---------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226fe2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Input configuration\n",
    "excel_file_path = \"auditor_and_liquidator.xlsx\"\n",
    "auditor_sheetname = \"REG_AUDITOR_202511\"\n",
    "liquidator_sheetname = \"LIQUIDATOR_202510\"\n",
    "\n",
    "output_folder = \"destination/excel\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46cfea",
   "metadata": {},
   "source": [
    "Read Auditor data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbca6dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         REGISTER_NAME  REG_AUD_NUM               REG_AUD_NAME  REG_AUD_ACN  \\\n",
      "0  Registered Auditors       339233  A D DANIELI AUDIT PTY LTD  136616610.0   \n",
      "1  Registered Auditors       486826    ABBOTT, ALASTAIR GORDON          NaN   \n",
      "2  Registered Auditors       517142       ABBOTT, BELINDA KATE          NaN   \n",
      "3  Registered Auditors       155449      ABBOTT, DALE GEOFFREY          NaN   \n",
      "4  Registered Auditors       479572         ABBOTT, DAVID GREG          NaN   \n",
      "\n",
      "  REG_AUD_START_DT REG_AUD_STATUS REG_AUD_SUSP_DT REG_AUD_ADD_LOCAL  \\\n",
      "0       24/07/2009           APPR             NaN           SYDNEY    \n",
      "1       10/05/2016           APPR             NaN       EAST PERTH    \n",
      "2       17/07/2019           APPR             NaN     MALVERN EAST    \n",
      "3       17/07/1995           APPR             NaN         NARROGIN    \n",
      "4       19/10/2015           APPR             NaN         BALLARAT    \n",
      "\n",
      "  REG_AUD_ADD_STATE  REG_AUD_ADD_PCODE REG_AUD_ADD_COUNTRY  \n",
      "0               NSW             2000.0           Australia  \n",
      "1                WA             6004.0           Australia  \n",
      "2               VIC             3145.0           Australia  \n",
      "3                WA             6312.0           Australia  \n",
      "4               VIC             3350.0           Australia  \n"
     ]
    }
   ],
   "source": [
    "# Read data from \"REG_AUDITOR_202511\" spreadsheet with header starting on row 3\n",
    "df = pd.read_excel(excel_file_path, sheet_name=auditor_sheetname, header=2)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c94f86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REGISTER_NAME           object\n",
      "REG_AUD_NUM              int64\n",
      "REG_AUD_NAME            object\n",
      "REG_AUD_ACN            float64\n",
      "REG_AUD_START_DT        object\n",
      "REG_AUD_STATUS          object\n",
      "REG_AUD_SUSP_DT         object\n",
      "REG_AUD_ADD_LOCAL       object\n",
      "REG_AUD_ADD_STATE       object\n",
      "REG_AUD_ADD_PCODE      float64\n",
      "REG_AUD_ADD_COUNTRY     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect column types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7956575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric identifier columns to string\n",
    "cols_to_str = ['REG_AUD_NUM', 'REG_AUD_ACN', 'REG_AUD_ADD_PCODE']\n",
    "\n",
    "for col in cols_to_str:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('Int64').astype(str)\n",
    "\n",
    "# Convert date columns to datetime (DD/MM/YYYY format)\n",
    "date_cols = ['REG_AUD_START_DT', 'REG_AUD_SUSP_DT ']\n",
    "\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n",
    "        # df[col] = pd.to_datetime(df[col], format=\"%Y-%m-%d\", errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843f6cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV exported successfully to: destination/excel\\auditor.csv\n"
     ]
    }
   ],
   "source": [
    "# Export to CSV\n",
    "output_file = \"auditor.csv\"\n",
    "auditor_output_path = os.path.join(output_folder, output_file)\n",
    "\n",
    "df.to_csv(auditor_output_path, index=False, date_format='%d/%m/%Y')\n",
    "\n",
    "print(f\"CSV exported successfully to: {auditor_output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8d8036",
   "metadata": {},
   "source": [
    "Read Liquidator data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5e03f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liquidator CSV exported successfully to: destination/excel\\liquidator.csv\n"
     ]
    }
   ],
   "source": [
    "# Define schema for data types\n",
    "liquidator_schema = {\n",
    "    \"REGISTER_NAME\": str,\n",
    "    \"LIQ_NUM\": str,\n",
    "    \"OFF_LIQ_NUM\": str,\n",
    "    \"LIQ_NAME\": str,\n",
    "    \"LIQ_START_DT\": 'datetime64[ns]',\n",
    "    \"OFF_LIQ_START_DT\": 'datetime64[ns]',\n",
    "    \"LIQ_STATUS\": str,\n",
    "    \"LIQ_SUSP_DT\": 'datetime64[ns]',\n",
    "    \"LIQ_ADD_LOCAL\": str,\n",
    "    \"LIQ_ADD_STATE\": str,\n",
    "    \"LIQ_ADD_PCODE\": str,\n",
    "    \"LIQ_ADD_COUNTRY\": str,\n",
    "    \"LIQ_FIRM\": str\n",
    "}\n",
    "\n",
    "# Read data from \"LIQUIDATOR_202510\" spreadsheet \n",
    "df_liq = pd.read_excel(excel_file_path, \n",
    "                       sheet_name=liquidator_sheetname, \n",
    "                       header=2, \n",
    "                       dtype=liquidator_schema)\n",
    "\n",
    "# Convert date columns to datetime\n",
    "date_cols = [\"LIQ_START_DT\", \"OFF_LIQ_START_DT\", \"LIQ_SUSP_DT\"]\n",
    "\n",
    "for col in date_cols:\n",
    "    if col in df_liq.columns:\n",
    "        df_liq[col] = pd.to_datetime(df_liq[col], errors='coerce', dayfirst=True)\n",
    "\n",
    "\n",
    "# Export to CSV \n",
    "output_file = \"liquidator.csv\"\n",
    "liquidator_output_path = os.path.join(output_folder, output_file)\n",
    "\n",
    "df_liq.to_csv(liquidator_output_path, index=False, date_format='%d/%m/%Y')\n",
    "\n",
    "print(f\"Liquidator CSV exported successfully to: {liquidator_output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
